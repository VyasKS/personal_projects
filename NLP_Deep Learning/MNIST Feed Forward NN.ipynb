{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network on MNIST dataset -  a simple reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784              # Input of 28x28 pixels = 784 features\n",
    "hidden_size = 400             # no of neurons in hidden layer\n",
    "output_size = 10              # classification of 0-9 digits hence, 10 neurons\n",
    "epochs = 10                   # we show data to the model 10 times\n",
    "batch_size = 100              # in a batch of 100 per iteration\n",
    "learning_rate = 0.001         # how fast we're moving towards optimum during optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = datasets.MNIST(root = './data', train = True, transform = transforms.ToTensor(), download = True)\n",
    "test_set = datasets.MNIST(root = './data', train = False, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = training_set, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_set, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn mnist](https://user-images.githubusercontent.com/30661597/61593615-5eb8bf00-ac14-11e9-8087-f880971b3543.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our network architecture is very simple one with just 3 layers. Input with 784 neurons, hidden with 400 and finally output layer for predicting which class those digits belong to with 10 neurons. We use ReLU function as activation for all layers.\n",
    "\n",
    "\n",
    "\n",
    "### Building the Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \n",
    "        \"\"\" Initializes our Model class with attributes and objects inherited from nn.Module class which already has many pre-determined functions\"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        # Input layer\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        # Hidden Layer\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        # Output layer\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "        \n",
    "    \n",
    "    def init_weights(self):\n",
    "        \"\"\" Initializes weights for forward propogation for both input and hidden layer. We don't need to initialize for output_layer\"\"\"\n",
    "        nn.init.kaiming_normal(self.fc1.weight)\n",
    "        nn.init.kaiming_normal(self.fc2.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\" Forward propogation through the layers\"\"\"\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-f72a6910a0aa>:19: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(self.fc1.weight)\n",
      "<ipython-input-10-f72a6910a0aa>:20: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(self.fc2.weight)\n"
     ]
    }
   ],
   "source": [
    "# Create an object for our model to be called as\n",
    "net = Model(input_size = input_size, hidden_size = hidden_size, output_size = output_size)\n",
    "CUDA = torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    net = net.cuda\n",
    "# Loss function is Cross Entropy loss for multi class classification. No need to specify Softmax () as it comes along with it.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Calling Adam optmiizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.086, Training Accuracy: 97.352%\n",
      "Epoch [2/10], Training Loss: 0.055, Training Accuracy: 98.243%\n",
      "Epoch [3/10], Training Loss: 0.040, Training Accuracy: 98.670%\n",
      "Epoch [4/10], Training Loss: 0.028, Training Accuracy: 99.082%\n",
      "Epoch [5/10], Training Loss: 0.024, Training Accuracy: 99.228%\n",
      "Epoch [6/10], Training Loss: 0.020, Training Accuracy: 99.320%\n",
      "Epoch [7/10], Training Loss: 0.015, Training Accuracy: 99.478%\n",
      "Epoch [8/10], Training Loss: 0.016, Training Accuracy: 99.470%\n",
      "Epoch [9/10], Training Loss: 0.014, Training Accuracy: 99.538%\n",
      "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 99.602%\n",
      ">>>>>NETWORK FINISHED TRAINING!<<<<<<<<<\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    correct_train = 0\n",
    "    running_loss = 0\n",
    "    for i , (images, labels) in enumerate(train_loader):\n",
    "        \"\"\" Flatten the image from size (batch,1,28,28) --> (100,1,28,28) where 1 represents the number of channels (grayscale-->1),\n",
    "         to size (100,784) and wrap it in a variable \"\"\"\n",
    "        \n",
    "        images = images.view(-1, 28*28)    \n",
    "        \n",
    "        if CUDA:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct_train += (predicted == labels).sum()\n",
    "        loss = criterion(outputs, labels)                  # Difference between actual and predicted is the loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()                              # Flush existing gradients to avoid accumulation\n",
    "        loss.backward()                                    # Compute gradients\n",
    "        optimizer.step()                                   # Update weights\n",
    "        \n",
    "    print('Epoch [{}/{}], Training Loss: {:.3f}, Training Accuracy: {:.3f}%'.format\n",
    "          (epoch+1, epochs, running_loss/len(train_loader), (100*correct_train.double()/len(training_set))))\n",
    "print(\">>>>>NETWORK FINISHED TRAINING!<<<<<<<<<\")   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.07 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for images, labels in test_loader:\n",
    "        if CUDA:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "        images = images.view(-1, 28*28)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / len(test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###                                                                           THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
